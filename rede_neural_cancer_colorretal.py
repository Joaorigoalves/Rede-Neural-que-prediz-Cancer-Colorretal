# -*- coding: utf-8 -*-
"""Rede_Neural_cancer_colorretal

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RvKr901u-zUkRdjmcD-9ELNnOxZZAZYt
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow_datasets as tfds
from keras import models,layers
from sklearn.preprocessing import label_binarize
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay

np.random.seed(1)
image_size = 150 # width and length
no_of_different_labels = 8 #  i.e. 0, 1, 2, 3, ..., 8
image_pixels = image_size * image_size

# 1. CARREGAR DATASET
dataset = tfds.load('colorectal_histology', split='train')
dataset_list = list(dataset)
np.random.shuffle(dataset_list)

print(f"Total de imagens: {len(dataset_list)}")

# 2. DIVIDIR TREINO/TESTE
train_size = int(0.8 * len(dataset_list))
train_data = dataset_list[:train_size]
test_data = dataset_list[train_size:]

print(f"Treino: {len(train_data)} imagens")
print(f"Teste: {len(test_data)} imagens")

# 3. EXTRAIR IMAGENS E LABELS
train_imgs = np.array([item['image'].numpy() for item in train_data])
test_imgs = np.array([item['image'].numpy() for item in test_data])
train_labels = np.array([item['0label'].numpy() for item in train_data])
test_labels = np.array([item['label'].numpy() for item in test_data])

print(f"✅ Train images: {train_imgs.shape}")
print(f"✅ Test images: {test_imgs.shape}")
print(f"✅ Train labels: {train_labels.shape}")
print(f"✅ Test labels: {test_labels.shape}")

#4. NORMALIZAÇÃO CORRETA
train_imgs = train_imgs / 255.0
test_imgs = test_imgs / 255.0

# 5. BINARIZAR LABELS
train_labels_bin = label_binarize(train_labels, classes=[0, 1, 2, 3, 4, 5, 6, 7])
test_labels_bin = label_binarize(test_labels, classes=[0, 1, 2, 3, 4, 5, 6, 7])

print(f"✅ Train labels binarized: {train_labels_bin.shape}")
print(f"✅ Test labels binarized: {test_labels_bin.shape}")

import matplotlib.pyplot as plt

fig, ax = plt.subplots(nrows=5, ncols=4, figsize=(12, 15))

for i in range(5):
    for j in range(4):
        idx = i * 4 + j
        if idx < len(train_data):
            # Para Colorectal Histology:
            img = train_data[idx]['image'].numpy()  # Já é (150, 150, 3)

            ax[i,j].imshow(img)
            ax[i,j].title.set_text(f"Class: {train_data[idx]['label'].numpy()}")
            ax[i,j].axis('off')

plt.tight_layout()
plt.show()

from tensorflow.keras import regularizers
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

callbacks = [
    EarlyStopping(
        monitor='val_accuracy',
        mode='max',
        patience=15,
        restore_best_weights=True,
        verbose=1
    ),
    ReduceLROnPlateau(
        monitor='val_loss',
        mode='min',
        patience=8,
        factor=0.5,
        min_lr=0.000001,
        verbose=1
    )
]

model = models.Sequential([
    layers.Input(shape=(150, 150, 3)),

    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),

    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),

    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
    layers.GlobalAveragePooling2D(),
    layers.Dropout(0.5),

    layers.Dense(256, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.4),

    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),

    layers.Dense(8, activation='softmax')
])


model.compile(
    optimizer=tf.keras.optimizers.Adam(0.001),
    loss='categorical_crossentropy',
    metrics=[tf.keras.metrics.CategoricalAccuracy()]
)

history = model.fit(
    train_imgs, train_labels_bin,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=callbacks,
    verbose=1
)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Function')
plt.ylabel('Categorical Cross Entropy')
plt.xlabel('Epoch')
plt.legend(['Training Error','Validation Error'], loc='upper right')
plt.savefig("trainingerror.pdf")
plt.show()

plt.plot(history.history['categorical_accuracy'])
plt.plot(history.history['val_categorical_accuracy'])
plt.title('Training Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Training','Validation'], loc='lower right')
plt.savefig("trainingaccuracy.pdf")
plt.show()
print("Training Accuracy:", round(history.history['categorical_accuracy'][-1],4))
print("Validation Accuracy:", round(history.history['val_categorical_accuracy'][-1],4))

print(f"Shape test_labels_bin: {test_labels_bin.shape}")

scores = model.evaluate(
    test_imgs, test_labels_bin, verbose=1
)

print("%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))

test_predictions = model.predict(test_imgs)
print(confusion_matrix(test_predictions.argmax(axis=1), test_labels_bin.argmax(axis=1)))
print(classification_report(test_predictions.argmax(axis=1), test_labels_bin.argmax(axis=1), target_names=[  'epitélio tumoral',
    'estroma simples',
    'estroma complexo',
    'células imunológicas',
    'resíduos e muco',
    'glândulas mucosas',
    'tecido adiposo',
    'fundo']))

cm = confusion_matrix(test_predictions.argmax(axis=1), test_labels_bin.argmax(axis=1))
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[  'epitélio tumoral',
    'estroma simples',
    'estroma complexo',
    'células imunológicas',
    'resíduos e muco',
    'glândulas mucosas',
    'tecido adiposo',
    'fundo'])
disp.plot(cmap="Blues")
plt.title('Confusion Matrix for Testing Set')
plt.savefig("confusionmatrix.pdf")
plt.show()

i = 0
j = -1

fig, ax = plt.subplots(nrows=8, ncols=6, figsize=(15, 20))

for k in range(len(test_imgs)):
    if test_predictions.argmax(axis=1)[k] != test_labels_bin.argmax(axis=1)[k]:
        if i == 8:
            break
        j = j + 1

        img = test_imgs[k]


        if img.max() <= 1.0:
            img = (img * 255).astype('uint8')

        ax[i,j].imshow(img)

        true_label = test_labels[k]
        pred_label = test_predictions.argmax(axis=1)[k]
        ax[i,j].title.set_text(f"True: {true_label}, Pred: {pred_label}")
        ax[i,j].axis('off')

        if j >= 5:
            j = -1
            i = i + 1

for idx in range(i*6 + j + 1, 48):
    ax.flatten()[idx].axis('off')

plt.tight_layout()
plt.show()

fig, axes = plt.subplots(nrows=6, ncols=4, figsize=(16, 20))

for z in range(24):
    kernel = model.layers[0].kernel[:, :, :, z].numpy()

    kernel_channel = kernel[:, :, 0]

    im = axes[z//4, z%4].imshow(kernel_channel, cmap="coolwarm")
    axes[z//4, z%4].set_title(f'Kernel {z+1}\nMin: {kernel_channel.min():.3f}\nMax: {kernel_channel.max():.3f}', fontsize=9)
    axes[z//4, z%4].axis('off')

        plt.colorbar(im, ax=axes[z//4, z%4], fraction=0.046)

plt.tight_layout()
plt.show()